# Baseline 算法的 python 化脚本

## baseline算法的基本步骤

1). 数据平滑：数据平滑的作用是减少由于统计因素造成的数据局域过低现象。平滑线反应数据的主体走势，忽略了统计过程中产生的信号波动。这样有助于使采样样本反应数据主体走势，降低了统计条件对算法结果的影响。平滑参数为：lambda

2). 数据采样：对平滑之后的数据进行均匀的二次采样，方式为采样区间中的最小值（导致结果偏低的原因）。采样数由参数 int 控制。之后的处理均采用该采样。

3). 抑制迭代：迭代次数由参数 it 设置。迭代方式为可重叠窗口的平均值与原值取最小的方法。窗口宽度随迭代次数依次以指数降低。窗口初始宽度用参数 hwi 设置。

4). 数据还原：通过插值法将采样结果还原。


## baseline应用于时域分析的适应性改进

### python 化 baseline 算法-改进 baseline 算法拟合偏低

代码参考了baseline的R代码编写的相同功能的代码，主要用于实现baseline算法的基本功能。但是不同的是我们采用了whitttaker平滑器取代了R代码中使用的平滑器。该平滑器的更改不影响最终效果。由于更改了平滑器，平滑参数的设置有所更改，平滑参数越大，数据越平滑。

为解决baseline算法估计背景基线偏低的问题，将最小采样变为平均值采样。这样可以有效减少背景基线偏低的问题。

### python 代码优化--提升计算速度

降低第一版本算法在迭代过程中创建索引数组的次数，通过切片方式进行采样。numpy数组求平均值时利用数组自带的求平均值函数（arr.mean() 要比 numpy.mean(arr) 快），对列表求最小值时利用python自带的函数（min(list) 要比 numpy.min(list) 快）。相同数据相同迭代次数，比R提速70% 。


### 解决时域数据边缘效应对 baseline 算法的影响。

利用whitttaker平滑器的性质，通过一些统计策略忽略数据边缘下降的情况。具体操作集合在get_smooth中。集体方法通过3次迭代，依次排除 1 sigma，2 sigma，3 sigma 的数据。虽然平滑的最终结果会忽视掉一些数据比较极端的凸起或凹陷，但是将贴合背景主体，在时域背景的估算中，这是合理且必要的。

同时我们对参数进行了优化，通过多次尝试，我们发现迭代次数为5时算法的时域适应性最好，大于5时容易引起背景基线偏低（但是并不会偏得太多），小于5时容易导致背景基线不平坦。




